{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824a1bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded scran-normalized data: (39726, 8000)\n",
      "‚úÖ Filtered to mapped cell lines: (39726, 8001)\n",
      "‚úÖ Aggregated pseudobulk (mean, scran-normalized): (140, 8000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# üì• Load scran-normalized matrix from parquet (cells √ó genes)\n",
    "umi_df = pd.read_parquet(\"../../data/processed/pancancer_scran_norm_top8000.parquet\")\n",
    "print(\"‚úÖ Loaded scran-normalized data:\", umi_df.shape)\n",
    "\n",
    "# üì• Load mapping file (Cell line ‚Üí SANGER_MODEL_ID)\n",
    "mapping_df = pd.read_csv(\"../../data/cell_sanger_map.csv\").drop_duplicates()\n",
    "mapping_df.columns = ['SANGER_MODEL_ID', 'CELL_LINE_NAME']\n",
    "mapping_df['CELL_LINE_NAME_NORM'] = mapping_df['CELL_LINE_NAME'].str.replace('-', '', regex=False).str.upper()\n",
    "\n",
    "# üîç Extract cell line name from cell barcodes\n",
    "umi_df.index = umi_df.index.astype(str)\n",
    "cell_line = umi_df.index.str.split('_').str[0]\n",
    "cell_line_norm = cell_line.str.replace('-', '', regex=False).str.upper()\n",
    "\n",
    "# üó∫Ô∏è Map normalized names to SANGER_MODEL_ID\n",
    "name_to_sidm = dict(zip(mapping_df['CELL_LINE_NAME_NORM'], mapping_df['SANGER_MODEL_ID']))\n",
    "sidm = cell_line_norm.map(name_to_sidm)\n",
    "\n",
    "# üßπ Keep only mapped cells\n",
    "mask = sidm.notna()\n",
    "umi_df = umi_df.loc[mask].copy()\n",
    "umi_df[\"SANGER_MODEL_ID\"] = sidm[mask].values\n",
    "\n",
    "print(\"‚úÖ Filtered to mapped cell lines:\", umi_df.shape)\n",
    "\n",
    "# üìä Aggregate into pseudobulk (mean expression per SANGER_MODEL_ID)\n",
    "pseudobulk_df = umi_df.groupby(\"SANGER_MODEL_ID\").mean()\n",
    "\n",
    "print(\"‚úÖ Aggregated pseudobulk (mean, scran-normalized):\", pseudobulk_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f85f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PCA applied: shape = (140, 30)\n",
      "üíæ Saved pseudobulk scran-normalized PCA(30) to:\n",
      "- ../../data/processed/pancancer_scran_norm_top8000_30_pcs.parquet\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pseudobulk_df = pseudobulk_df.dropna(axis=1, how=\"any\")\n",
    "\n",
    "# üéØ Apply PCA (30 components)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(pseudobulk_df)\n",
    "\n",
    "pca = PCA(n_components=30, random_state=42)\n",
    "pcs = pca.fit_transform(X_scaled)\n",
    "\n",
    "pcs_df = pd.DataFrame(\n",
    "    pcs,\n",
    "    index=pseudobulk_df.index,\n",
    "    columns=[f\"PC{i+1}\" for i in range(30)]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ PCA applied: shape =\", pcs_df.shape)\n",
    "\n",
    "# üíæ Save PCA-reduced pseudobulk\n",
    "parquet_path = \"../../data/processed/pancancer_scran_norm_top8000_30_pcs.parquet\"\n",
    "pcs_df.to_parquet(parquet_path, engine=\"pyarrow\", compression=\"snappy\")\n",
    "\n",
    "print(f\"üíæ Saved pseudobulk scran-normalized PCA(30) to:\\n- {parquet_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tese-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
