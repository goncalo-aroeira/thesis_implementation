{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c3c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: config\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import re\n",
    "from typing import Dict, Sequence, Optional, List\n",
    "\n",
    "# paths\n",
    "SC_PARQUET     = \"../../data/filtered_datasets/sc_overlap_genes.parquet\"\n",
    "SHORTLIST_CSV  = \"out/shortlist.csv\"   # <- update if you saved it elsewhere\n",
    "MODEL_DIR      = \"models\"\n",
    "\n",
    "# outputs\n",
    "OUT_PRED_PARQUET = \"out/per_cell_predictions.parquet\"\n",
    "OUT_SUMMARY_CSV  = \"out/summaries.csv\"\n",
    "os.makedirs(\"out\", exist_ok=True)\n",
    "\n",
    "# optional calibration table (columns: drug_id,slope,intercept) — set to None if not used\n",
    "CALIBRATION_CSV = None  # e.g., \"data/calibration_coeffs.csv\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# optional calibration table (columns: drug_id,slope,intercept)\n",
    "CALIBRATION_CSV = \"out/calibration_coeffs.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a344e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: helpers\n",
    "\n",
    "def load_sc_df(sc_parquet: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load single-cell matrix. Rows = cells, index = SANGER_MODEL_ID (repeated per cell).\n",
    "    Returns df with numeric gene columns; adds a synthetic 'cell_id' column.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(sc_parquet)\n",
    "    if df.index.name != \"SANGER_MODEL_ID\":\n",
    "        # if needed, rename; but your printout shows it's already SANGER_MODEL_ID\n",
    "        df.index.name = \"SANGER_MODEL_ID\"\n",
    "\n",
    "    # generate a unique cell_id since the index repeats\n",
    "    seq = df.groupby(level=0).cumcount().astype(str)\n",
    "    df.insert(0, \"cell_id\", df.index.astype(str) + \"__\" + seq)\n",
    "\n",
    "    # ensure gene columns are numeric\n",
    "    for c in df.columns:\n",
    "        if c == \"cell_id\":\n",
    "            continue\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def available_models(model_dir: str, allowed_drugs: Optional[Sequence[str]] = None) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Find bundles like elasticnet_drug1845.joblib, drug427.joblib, 1526.joblib, etc.\n",
    "    Returns {drug_id_str: path}\n",
    "    \"\"\"\n",
    "    paths: Dict[str, str] = {}\n",
    "    if not (model_dir and os.path.isdir(model_dir)):\n",
    "        return paths\n",
    "    allow = None if allowed_drugs is None else set(map(str, allowed_drugs))\n",
    "    for fname in os.listdir(model_dir):\n",
    "        if not fname.endswith(\".joblib\"):\n",
    "            continue\n",
    "        m = re.search(r'(\\d+)\\.joblib$', fname)\n",
    "        if not m:\n",
    "            continue\n",
    "        drug_id = m.group(1)\n",
    "        if (allow is None) or (drug_id in allow):\n",
    "            paths[drug_id] = os.path.join(model_dir, fname)\n",
    "    return paths\n",
    "\n",
    "def load_bundle(path: str) -> dict:\n",
    "    bundle = joblib.load(path)\n",
    "    for k in (\"model\", \"scaler\", \"gene_cols\"):\n",
    "        if k not in bundle:\n",
    "            raise KeyError(f\"Bundle at {path} missing key: {k}\")\n",
    "    bundle[\"gene_cols\"] = [str(g) for g in bundle[\"gene_cols\"]]\n",
    "    return bundle\n",
    "\n",
    "def align_features(sc_block: pd.DataFrame, gene_cols: Sequence[str], fill_missing: float = 0.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return sc_block with columns exactly in gene_cols order.\n",
    "    Missing genes are added with constant fill; extras are dropped.\n",
    "    \"\"\"\n",
    "    gene_cols = [str(g) for g in gene_cols]\n",
    "    present = [g for g in gene_cols if g in sc_block.columns]\n",
    "    missing = [g for g in gene_cols if g not in sc_block.columns]\n",
    "    X = sc_block.reindex(columns=present).copy()\n",
    "    if missing:\n",
    "        X = pd.concat([X, pd.DataFrame(fill_missing, index=sc_block.index, columns=missing)], axis=1)\n",
    "    X = X.loc[:, gene_cols]\n",
    "    return X\n",
    "\n",
    "def summarize_vector(y: np.ndarray) -> dict:\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if y.size == 0:\n",
    "        return dict(n=0, mean=np.nan, median=np.nan, sd=np.nan, q10=np.nan, q90=np.nan)\n",
    "    return {\n",
    "        \"n\": int(y.size),\n",
    "        \"mean\": float(np.mean(y)),\n",
    "        \"median\": float(np.median(y)),\n",
    "        \"sd\": float(np.std(y, ddof=1)) if y.size > 1 else np.nan,\n",
    "        \"q10\": float(np.quantile(y, 0.10)),\n",
    "        \"q90\": float(np.quantile(y, 0.90)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff7823fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: load sc + shortlist + (optional) calibration\n",
    "\n",
    "sc = load_sc_df(SC_PARQUET)  # has columns: cell_id, genes..., index=SANGER_MODEL_ID\n",
    "shortlist = pd.read_csv(SHORTLIST_CSV, dtype={\n",
    "    \"SANGER_MODEL_ID\": str,\n",
    "    \"low_drug\": str,\n",
    "    \"high_drug\": str\n",
    "})\n",
    "\n",
    "calib = None\n",
    "if CALIBRATION_CSV and os.path.exists(CALIBRATION_CSV):\n",
    "    calib = pd.read_csv(CALIBRATION_CSV, dtype={\"drug_id\": str}).set_index(\"drug_id\")\n",
    "    # sanity\n",
    "    for col in (\"slope\", \"intercept\"):\n",
    "        if col not in calib.columns:\n",
    "            raise KeyError(f\"Calibration CSV missing column: {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fff443e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for 13 lines × 2 drugs (low/high)…\n",
      "Made 24,350 per-cell predictions across 26 (line,drug) pairs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        cell_id SANGER_MODEL_ID drug_id    y_pred\n",
       " 0  SIDM00872__0       SIDM00872    1845  1.023117\n",
       " 1  SIDM00872__1       SIDM00872    1845  0.769557\n",
       " 2  SIDM00872__2       SIDM00872    1845  0.277932\n",
       " 3  SIDM00872__3       SIDM00872    1845  0.719935\n",
       " 4  SIDM00872__4       SIDM00872    1845  0.826301,\n",
       "       n      mean    median        sd       q10       q90 SANGER_MODEL_ID  \\\n",
       " 0  1623  0.882667  0.884405  0.302596  0.497564  1.263792       SIDM00872   \n",
       " 1  1623  4.158027  4.152576  0.229049  3.885130  4.438769       SIDM00872   \n",
       " 2   568  1.402018  1.370122  0.363885  0.972862  1.888719       SIDM01037   \n",
       " 3   568  3.256128  3.247564  0.259673  2.927773  3.594750       SIDM01037   \n",
       " 4  1280  1.506137  1.501434  0.173338  1.288101  1.724522       SIDM00866   \n",
       " \n",
       "   drug_id  \n",
       " 0    1845  \n",
       " 1    1089  \n",
       " 2    1845  \n",
       " 3    1096  \n",
       " 4    1526  )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% \n",
    "# Cell 4: prediction loop (with optional per-drug calibration)\n",
    "\n",
    "# discover available models for the drugs in the shortlist\n",
    "needed_drugs = set(shortlist[\"low_drug\"].astype(str)).union(set(shortlist[\"high_drug\"].astype(str)))\n",
    "model_paths = available_models(MODEL_DIR, allowed_drugs=sorted(needed_drugs))\n",
    "if not model_paths:\n",
    "    raise ValueError(\"No matching model bundles found for drugs in shortlist.\")\n",
    "\n",
    "pred_rows: List[pd.DataFrame] = []\n",
    "summary_rows: List[dict] = []\n",
    "\n",
    "# speed: precompute line -> row indices (sc.index is SANGER_MODEL_ID)\n",
    "line_to_idx = {line: np.where(sc.index.values == line)[0] for line in sc.index.unique()}\n",
    "\n",
    "# tiny helper for calibration lookup\n",
    "def apply_calibration(drug_id: str, y: np.ndarray) -> np.ndarray:\n",
    "    if calib is None: \n",
    "        return y\n",
    "    if drug_id in calib.index:\n",
    "        slope = float(calib.loc[drug_id, \"slope\"])\n",
    "        intercept = float(calib.loc[drug_id, \"intercept\"])\n",
    "        return slope * y + intercept\n",
    "    return y  # fallback to uncalibrated if missing\n",
    "\n",
    "print(f\"Running predictions for {len(shortlist)} lines × 2 drugs (low/high)…\")\n",
    "for _, row in shortlist.iterrows():\n",
    "    line = str(row[\"SANGER_MODEL_ID\"])\n",
    "    for drug_col in (\"low_drug\", \"high_drug\"):\n",
    "        drug_id = str(row[drug_col])\n",
    "\n",
    "        # skip if model missing\n",
    "        if drug_id not in model_paths:\n",
    "            print(f\"[WARN] Missing model for drug {drug_id}; skipping ({line}).\")\n",
    "            continue\n",
    "\n",
    "        # subset cells for this line\n",
    "        idx = line_to_idx.get(line, None)\n",
    "        if idx is None or len(idx) == 0:\n",
    "            print(f\"[WARN] No cells found for line {line}; skipping.\")\n",
    "            continue\n",
    "        sc_block = sc.iloc[idx, :]\n",
    "\n",
    "        # gene-only matrix (drop metadata like 'cell_id')\n",
    "        gene_cols_in_sc = [c for c in sc_block.columns if c != \"cell_id\"]\n",
    "\n",
    "        # load model bundle & align features\n",
    "        bundle = load_bundle(model_paths[drug_id])\n",
    "        X_df = align_features(sc_block[gene_cols_in_sc], bundle[\"gene_cols\"], fill_missing=0.0)\n",
    "        X = X_df.values\n",
    "\n",
    "        # transform & predict\n",
    "        Xs = bundle[\"scaler\"].transform(X)\n",
    "        y_pred = bundle[\"model\"].predict(Xs)\n",
    "\n",
    "        # optional per-drug linear calibration\n",
    "        y_pred = apply_calibration(drug_id, y_pred)\n",
    "\n",
    "        # collect per-cell predictions\n",
    "        pred_rows.append(pd.DataFrame({\n",
    "            \"cell_id\": sc_block[\"cell_id\"].values,\n",
    "            \"SANGER_MODEL_ID\": line,\n",
    "            \"drug_id\": drug_id,\n",
    "            \"y_pred\": y_pred.astype(float),\n",
    "        }))\n",
    "\n",
    "        # per (line, drug) summary\n",
    "        stats = summarize_vector(y_pred)\n",
    "        stats.update({\"SANGER_MODEL_ID\": line, \"drug_id\": drug_id})\n",
    "        summary_rows.append(stats)\n",
    "\n",
    "# concatenate outputs\n",
    "preds = (pd.concat(pred_rows, axis=0, ignore_index=True)\n",
    "         if pred_rows else pd.DataFrame(columns=[\"cell_id\",\"SANGER_MODEL_ID\",\"drug_id\",\"y_pred\"]))\n",
    "summaries = (pd.DataFrame(summary_rows)\n",
    "             if summary_rows else pd.DataFrame(columns=[\"SANGER_MODEL_ID\",\"drug_id\",\"n\",\"mean\",\"median\",\"sd\",\"q10\",\"q90\"]))\n",
    "\n",
    "print(f\"Made {len(preds):,} per-cell predictions across {preds[['SANGER_MODEL_ID','drug_id']].drop_duplicates().shape[0]} (line,drug) pairs.\")\n",
    "preds.head(), summaries.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28d8535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote per-cell predictions → out/per_cell_predictions.parquet (24350 rows)\n",
      "Wrote summaries → out/summaries.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: save\n",
    "if len(preds):\n",
    "    preds.to_parquet(OUT_PRED_PARQUET, index=False)\n",
    "    print(f\"Wrote per-cell predictions → {OUT_PRED_PARQUET} ({len(preds)} rows)\")\n",
    "else:\n",
    "    print(\"No predictions generated.\")\n",
    "\n",
    "if len(summaries):\n",
    "    summaries = summaries[[\"SANGER_MODEL_ID\", \"drug_id\", \"n\", \"mean\", \"median\", \"sd\", \"q10\", \"q90\"]]\n",
    "    summaries.to_csv(OUT_SUMMARY_CSV, index=False)\n",
    "    print(f\"Wrote summaries → {OUT_SUMMARY_CSV}\")\n",
    "else:\n",
    "    print(\"No summary rows generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tese-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
