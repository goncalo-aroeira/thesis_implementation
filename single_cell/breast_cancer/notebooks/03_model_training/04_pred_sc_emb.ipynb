{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53c3c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "SC_PARQUET       = \"../../data/filtered_datasets/breast_cancer_embeddings.parquet\"  # SANGER_MODEL_ID + emb_###\n",
    "SHORTLIST_CSV    = \"out/shortlist.csv\"\n",
    "MODEL_DIR        = \"embeddings\"   # where you saved the bulk models\n",
    "OUT_PRED_PARQUET = \"out/per_cell_predictions.parquet\"\n",
    "OUT_SUMMARY_CSV  = \"out/summaries.csv\"\n",
    "\n",
    "import os, re, joblib, numpy as np, pandas as pd\n",
    "from typing import Dict, Sequence, Optional, List\n",
    "os.makedirs(\"out\", exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a344e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sc_df(sc_parquet: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load single-cell EMBEDDINGS. Returns df with:\n",
    "      index = SANGER_MODEL_ID (repeated per cell),\n",
    "      columns = 'cell_id' (generated if missing) + emb_### features.\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(sc_parquet)\n",
    "\n",
    "    # Make sure we have SANGER_MODEL_ID as index\n",
    "    if \"SANGER_MODEL_ID\" in df.columns:\n",
    "        df = df.set_index(\"SANGER_MODEL_ID\")\n",
    "    if df.index.name != \"SANGER_MODEL_ID\":\n",
    "        df.index.name = \"SANGER_MODEL_ID\"\n",
    "\n",
    "    # Ensure a per-cell unique ID column\n",
    "    if \"cell_id\" not in df.columns:\n",
    "        seq = df.groupby(level=0).cumcount().astype(str)\n",
    "        df.insert(0, \"cell_id\", df.index.astype(str) + \"__\" + seq)\n",
    "\n",
    "    # Keep only embedding columns + cell_id\n",
    "    emb_cols = [c for c in df.columns if re.fullmatch(r\"emb_\\d+\", str(c))]\n",
    "    keep = [\"cell_id\"] + emb_cols\n",
    "    df = df[keep].copy()\n",
    "\n",
    "    # Cast embeddings to numeric (robust)\n",
    "    for c in emb_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def available_models(model_dir: str, allowed_drugs: Optional[Sequence[str]] = None) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Find model bundles by drug id inside MODEL_DIR.\n",
    "    Supports names like:\n",
    "      elasticnet_drug427_voomEmb.joblib\n",
    "      drug427.joblib\n",
    "      427.joblib\n",
    "    Returns {drug_id_str: path}\n",
    "    \"\"\"\n",
    "    paths: Dict[str, str] = {}\n",
    "    if not (model_dir and os.path.isdir(model_dir)):\n",
    "        return paths\n",
    "    allow = None if allowed_drugs is None else set(map(str, allowed_drugs))\n",
    "\n",
    "    for fname in os.listdir(model_dir):\n",
    "        if not fname.endswith(\".joblib\"):\n",
    "            continue\n",
    "        m = (re.search(r\"drug(\\d+)\", fname) or\n",
    "             re.search(r\"(\\d+)(?=\\.joblib$)\", fname))\n",
    "        if not m:\n",
    "            continue\n",
    "        drug_id = m.group(1)\n",
    "        if allow is None or drug_id in allow:\n",
    "            paths[drug_id] = os.path.join(model_dir, fname)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def load_bundle(path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load a trained model bundle from disk and normalize it to:\n",
    "        {\"pipeline\": <fitted-pipeline>, \"feature_cols\": [..]}\n",
    "    Supports:\n",
    "      - {\"pipeline\", \"feature_cols\"}                 # current\n",
    "      - {\"pipeline\", \"gene_cols\"}                    # your earlier save\n",
    "      - {\"model\",\"scaler\",\"gene_cols\"}               # legacy (no imputer)\n",
    "    \"\"\"\n",
    "    import joblib\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    b = joblib.load(path)\n",
    "\n",
    "    # Case 1: already has a pipeline\n",
    "    if isinstance(b, dict) and \"pipeline\" in b:\n",
    "        feats = b.get(\"feature_cols\") or b.get(\"gene_cols\") or b.get(\"emb_cols\")\n",
    "        if feats is None:\n",
    "            raise KeyError(f\"Bundle {path} has 'pipeline' but no feature names \"\n",
    "                           \"(expected 'feature_cols' or 'gene_cols').\")\n",
    "        return {\"pipeline\": b[\"pipeline\"], \"feature_cols\": [str(c) for c in feats]}\n",
    "\n",
    "    # Case 2: legacy dict with model+scaler(+genes)\n",
    "    if isinstance(b, dict) and {\"model\", \"scaler\", \"gene_cols\"}.issubset(b.keys()):\n",
    "        pipe = Pipeline([\n",
    "            (\"scale\", b[\"scaler\"]),\n",
    "            (\"model\", b[\"model\"]),\n",
    "        ])\n",
    "        return {\"pipeline\": pipe, \"feature_cols\": [str(c) for c in b[\"gene_cols\"]]}\n",
    "\n",
    "    # Case 3: someone saved the pipeline object directly\n",
    "    if hasattr(b, \"predict\") and hasattr(b, \"fit\"):\n",
    "        # We still need feature names to align columns\n",
    "        # try common sidecar keys if present\n",
    "        feats = getattr(b, \"feature_names_in_\", None)\n",
    "        if feats is not None:\n",
    "            return {\"pipeline\": b, \"feature_cols\": [str(c) for c in feats]}\n",
    "        raise KeyError(f\"Bundle {path} is a model/pipeline object without saved feature names.\")\n",
    "\n",
    "    raise KeyError(f\"Unrecognized bundle format at {path}.\")\n",
    "\n",
    "\n",
    "\n",
    "def align_features(frame: pd.DataFrame, needed_cols: Sequence[str], fill_missing: float = 0.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Align 'frame' to exactly the columns in 'needed_cols' (order preserved).\n",
    "    Missing cols are added with constant fill; extras dropped.\n",
    "    \"\"\"\n",
    "    needed = [str(c) for c in needed_cols]\n",
    "    present = [c for c in needed if c in frame.columns]\n",
    "    missing = [c for c in needed if c not in frame.columns]\n",
    "\n",
    "    X = frame.reindex(columns=present).copy()\n",
    "    if missing:\n",
    "        X = pd.concat([X, pd.DataFrame(fill_missing, index=frame.index, columns=missing)], axis=1)\n",
    "    return X[needed]\n",
    "\n",
    "\n",
    "def summarize_vector(y: np.ndarray) -> dict:\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if y.size == 0:\n",
    "        return dict(n=0, mean=np.nan, median=np.nan, sd=np.nan, q10=np.nan, q90=np.nan)\n",
    "    return {\n",
    "        \"n\": int(y.size),\n",
    "        \"mean\": float(np.mean(y)),\n",
    "        \"median\": float(np.median(y)),\n",
    "        \"sd\": float(np.std(y, ddof=1)) if y.size > 1 else np.nan,\n",
    "        \"q10\": float(np.quantile(y, 0.10)),\n",
    "        \"q90\": float(np.quantile(y, 0.90)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff7823fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 model(s) for 10 requested drug(s).\n"
     ]
    }
   ],
   "source": [
    "# Single-cell embeddings (rows=cells; index=SANGER_MODEL_ID)\n",
    "sc = load_sc_df(SC_PARQUET)\n",
    "\n",
    "# Shortlist with columns: SANGER_MODEL_ID, low_drug, high_drug\n",
    "shortlist = pd.read_csv(\n",
    "    SHORTLIST_CSV,\n",
    "    dtype={\"SANGER_MODEL_ID\": str, \"low_drug\": str, \"high_drug\": str}\n",
    ")\n",
    "\n",
    "# What drugs do we need models for?\n",
    "needed_drugs = set(shortlist[\"low_drug\"]).union(set(shortlist[\"high_drug\"]))\n",
    "model_paths = available_models(MODEL_DIR, allowed_drugs=sorted(needed_drugs))\n",
    "print(f\"Found {len(model_paths)} model(s) for {len(needed_drugs)} requested drug(s).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ffe4b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        cell_id SANGER_MODEL_ID drug_id     y_pred\n",
       " 0  SIDM00872__0       SIDM00872    1845  14.828639\n",
       " 1  SIDM00872__1       SIDM00872    1845  10.983622\n",
       " 2  SIDM00872__2       SIDM00872    1845   8.991213\n",
       " 3  SIDM00872__3       SIDM00872    1845  17.720463\n",
       " 4  SIDM00872__4       SIDM00872    1845  18.165287,\n",
       "       n       mean     median        sd        q10        q90 SANGER_MODEL_ID  \\\n",
       " 0  1612  15.045147  14.885859  3.430244  10.956575  19.193967       SIDM00872   \n",
       " 1  1612  19.455275  19.552840  1.848168  16.966412  21.716185       SIDM00872   \n",
       " 2   558  14.471709  14.217988  2.752169  11.447732  17.489128       SIDM01037   \n",
       " 3   558  16.862919  16.851243  2.874423  13.277205  20.609584       SIDM01037   \n",
       " 4  1279  -8.559445  -8.752190  1.861862 -10.815838  -5.975373       SIDM00866   \n",
       " \n",
       "   drug_id  \n",
       " 0    1845  \n",
       " 1    1089  \n",
       " 2    1845  \n",
       " 3    1096  \n",
       " 4    1526  )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rows: List[pd.DataFrame] = []\n",
    "summary_rows: List[dict] = []\n",
    "\n",
    "# Precompute fast lookup from line -> cell rows\n",
    "line_to_idx = {line: np.where(sc.index.values == line)[0] for line in sc.index.unique()}\n",
    "\n",
    "for _, row in shortlist.iterrows():\n",
    "    line = str(row[\"SANGER_MODEL_ID\"])\n",
    "    idx = line_to_idx.get(line, None)\n",
    "    if idx is None or len(idx) == 0:\n",
    "        print(f\"[WARN] No cells for line {line}; skipping both drugs.\")\n",
    "        continue\n",
    "\n",
    "    sc_block = sc.iloc[idx, :]\n",
    "    emb_cols_in_sc = [c for c in sc_block.columns if c != \"cell_id\"]\n",
    "\n",
    "    for drug_col in (\"low_drug\", \"high_drug\"):\n",
    "        drug_id = str(row[drug_col])\n",
    "\n",
    "        # skip if no model\n",
    "        if drug_id not in model_paths:\n",
    "            print(f\"[WARN] Missing model for drug {drug_id}; skipping.\")\n",
    "            continue\n",
    "\n",
    "        # load pipeline bundle & align features\n",
    "        bundle = load_bundle(model_paths[drug_id])\n",
    "        pipe = bundle[\"pipeline\"]\n",
    "        needed = bundle[\"feature_cols\"]   # embedding feature names used in training\n",
    "\n",
    "        X = align_features(sc_block[emb_cols_in_sc], needed, fill_missing=0.0)\n",
    "\n",
    "        # Predict directly with the pipeline (imputer+scaler+enet already inside)\n",
    "        y_pred = pipe.predict(X.values)\n",
    "\n",
    "        # collect per-cell predictions\n",
    "        pred_rows.append(pd.DataFrame({\n",
    "            \"cell_id\": sc_block[\"cell_id\"].values,\n",
    "            \"SANGER_MODEL_ID\": line,\n",
    "            \"drug_id\": drug_id,\n",
    "            \"y_pred\": y_pred,\n",
    "        }))\n",
    "\n",
    "        # (line, drug) summary\n",
    "        stats = summarize_vector(y_pred)\n",
    "        stats.update({\"SANGER_MODEL_ID\": line, \"drug_id\": drug_id})\n",
    "        summary_rows.append(stats)\n",
    "\n",
    "# Assemble outputs\n",
    "preds = pd.concat(pred_rows, axis=0, ignore_index=True) if pred_rows else pd.DataFrame(\n",
    "    columns=[\"cell_id\", \"SANGER_MODEL_ID\", \"drug_id\", \"y_pred\"]\n",
    ")\n",
    "summaries = pd.DataFrame(summary_rows) if summary_rows else pd.DataFrame(\n",
    "    columns=[\"SANGER_MODEL_ID\", \"drug_id\", \"n\", \"mean\", \"median\", \"sd\", \"q10\", \"q90\"]\n",
    ")\n",
    "\n",
    "preds.head(), summaries.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fff443e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Wrote per-cell predictions → out/per_cell_predictions.parquet (24132 rows)\n",
      "📝 Wrote summaries → out/summaries.csv\n"
     ]
    }
   ],
   "source": [
    "if len(preds):\n",
    "    preds.to_parquet(OUT_PRED_PARQUET, index=False)\n",
    "    print(f\"📝 Wrote per-cell predictions → {OUT_PRED_PARQUET} ({len(preds)} rows)\")\n",
    "else:\n",
    "    print(\"No predictions generated.\")\n",
    "\n",
    "if len(summaries):\n",
    "    summaries = summaries[[\"SANGER_MODEL_ID\", \"drug_id\", \"n\", \"mean\", \"median\", \"sd\", \"q10\", \"q90\"]]\n",
    "    summaries.to_csv(OUT_SUMMARY_CSV, index=False)\n",
    "    print(f\"📝 Wrote summaries → {OUT_SUMMARY_CSV}\")\n",
    "else:\n",
    "    print(\"No summary rows generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tese-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
