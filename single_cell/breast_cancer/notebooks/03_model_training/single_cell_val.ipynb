{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5afeae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.mixture import GaussianMixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0d9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (adjust if needed)\n",
    "MODELS_DIR       = \"../trained_models\"                                # elasticnet_drug{ID}.joblib\n",
    "SC_EXPR_PARQUET  = \"../../data/filtered_datasets/sc_overlap_genes.parquet\"    # cells Ã— genes (SIDG columns)\n",
    "SC_META_CSV      = \"../metadata/sc_cell_to_sanger.csv\"                # columns: cell_id, SANGER_MODEL_ID (optional, see fallback)\n",
    "GDSC_PARQUET     = \"../../../../bulk_state_of_the_art/data/processed/gdsc_final_cleaned.parquet\"\n",
    "CALIB_DIR        = \"../singlecell_validation_outputs\"                 # where calibration_drug{ID}.txt might be\n",
    "OUTDIR           = \"../singlecell_per_line_results\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "BEST_DRUGS = [1845, 2540, 2038, 2508, 1096, 1931, 2515, 1089, 427, 1526]  # or list(models present)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ac7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <<< SET THIS >>>\n",
    "SANGER_ID = \"XXXX\"   # e.g., \"SIDM00438\" or your SANGER_MODEL_ID string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae46a1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc_expr: (35276, 545)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'breast_cancer_raw_annotated.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m         m \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mreindex(sc_expr\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m m\n\u001b[0;32m---> 23\u001b[0m sc_to_sanger \u001b[38;5;241m=\u001b[39m \u001b[43mload_sc_to_sanger\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc_expr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMapped cells:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sc_to_sanger\u001b[38;5;241m.\u001b[39mnotna()\u001b[38;5;241m.\u001b[39msum(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sc_to_sanger))\n",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m, in \u001b[0;36mload_sc_to_sanger\u001b[0;34m(index_like, meta_csv)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscanpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m H5AD \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbreast_cancer_raw_annotated.h5ad\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# adjust if needed\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m adata \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_h5ad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH5AD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m obs \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mobs\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSANGER_MODEL_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mcolumns, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSANGER_MODEL_ID not found in obs; provide SC_META_CSV\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/tese-env/lib/python3.10/site-packages/anndata/_io/h5ad.py:239\u001b[0m, in \u001b[0;36mread_h5ad\u001b[0;34m(filename, backed, as_sparse, as_sparse_fmt, chunk_size)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[1;32m    235\u001b[0m rdasp \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    236\u001b[0m     read_dense_as_sparse, sparse_format\u001b[38;5;241m=\u001b[39mas_sparse_fmt, axis_chunk\u001b[38;5;241m=\u001b[39mchunk_size\n\u001b[1;32m    237\u001b[0m )\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcallback\u001b[39m(func, elem_name: \u001b[38;5;28mstr\u001b[39m, elem, iospec):\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m iospec\u001b[38;5;241m.\u001b[39mencoding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manndata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/tese-env/lib/python3.10/site-packages/h5py/_hl/files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.conda/envs/tese-env/lib/python3.10/site-packages/h5py/_hl/files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'breast_cancer_raw_annotated.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Load sc expression (cells Ã— SIDG genes)\n",
    "sc_expr = pd.read_parquet(SC_EXPR_PARQUET)\n",
    "print(\"sc_expr:\", sc_expr.shape)\n",
    "\n",
    "def load_sc_to_sanger(index_like, meta_csv=SC_META_CSV):\n",
    "    if meta_csv and os.path.exists(meta_csv):\n",
    "        meta = pd.read_csv(meta_csv).set_index(\"cell_id\")\n",
    "        assert \"SANGER_MODEL_ID\" in meta.columns\n",
    "        series = meta.loc[meta.index.intersection(index_like), \"SANGER_MODEL_ID\"].astype(str)\n",
    "        # Reindex to sc_expr in case order differs\n",
    "        return series.reindex(index_like)\n",
    "    else:\n",
    "        # Fallback: pull from AnnData obs if available\n",
    "        import scanpy as sc\n",
    "        H5AD = \"breast_cancer_raw_annotated.h5ad\"  # adjust if needed\n",
    "        adata = sc.read_h5ad(H5AD)\n",
    "        obs = adata.obs\n",
    "        assert \"SANGER_MODEL_ID\" in obs.columns, \"SANGER_MODEL_ID not found in obs; provide SC_META_CSV\"\n",
    "        m = obs[\"SANGER_MODEL_ID\"].astype(str)\n",
    "        m = m.reindex(sc_expr.index)\n",
    "        return m\n",
    "\n",
    "sc_to_sanger = load_sc_to_sanger(sc_expr.index)\n",
    "print(\"Mapped cells:\", sc_to_sanger.notna().sum(), \"/\", len(sc_to_sanger))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cb5edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_of_line = sc_to_sanger[sc_to_sanger == SANGER_ID].index\n",
    "assert len(cells_of_line) > 0, f\"No cells found for SANGER_MODEL_ID={SANGER_ID}\"\n",
    "sc_line = sc_expr.loc[cells_of_line]\n",
    "print(f\"Cells for {SANGER_ID}:\", sc_line.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdsc = pd.read_parquet(GDSC_PARQUET)\n",
    "gdsc = gdsc.dropna(subset=[\"SANGER_MODEL_ID\",\"DRUG_ID\",\"LN_IC50\"]).copy()\n",
    "gdsc[\"SANGER_MODEL_ID\"] = gdsc[\"SANGER_MODEL_ID\"].astype(str)\n",
    "\n",
    "gdsc_line = gdsc[(gdsc[\"SANGER_MODEL_ID\"] == SANGER_ID) & (gdsc[\"DRUG_ID\"].isin(BEST_DRUGS))][[\"DRUG_ID\",\"LN_IC50\"]]\n",
    "gdsc_line = gdsc_line.drop_duplicates(subset=[\"DRUG_ID\"])  # safety\n",
    "print(\"GDSC rows for this line:\", gdsc_line.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_calibration(drug_id, calib_dir=CALIB_DIR):\n",
    "    \"\"\"\n",
    "    Returns slope, intercept if a calibration file exists; else identity mapping.\n",
    "    File format: two lines 'slope\\t<...>' and 'intercept\\t<...>'.\n",
    "    \"\"\"\n",
    "    path = os.path.join(calib_dir, f\"calibration_drug{drug_id}.txt\")\n",
    "    if not os.path.exists(path):\n",
    "        return 1.0, 0.0\n",
    "    slope, intercept = 1.0, 0.0\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) == 2:\n",
    "                k, v = parts\n",
    "                if k == \"slope\": slope = float(v)\n",
    "                if k == \"intercept\": intercept = float(v)\n",
    "    return slope, intercept\n",
    "\n",
    "def heterogeneity_metrics(y_cell, random_state=42):\n",
    "    \"\"\"\n",
    "    Fit GMM with k=1..3 to per-cell predictions; return chosen k by BIC,\n",
    "    fraction of highest-mean component, and separation (max_mean - min_mean).\n",
    "    \"\"\"\n",
    "    y = np.asarray(y_cell).reshape(-1,1)\n",
    "    best_k, best_bic, best_gmm = 1, np.inf, None\n",
    "    for k in (1,2,3):\n",
    "        g = GaussianMixture(n_components=k, random_state=random_state).fit(y)\n",
    "        bic = g.bic(y)\n",
    "        if bic < best_bic:\n",
    "            best_k, best_bic, best_gmm = k, bic, g\n",
    "    means = best_gmm.means_.flatten()\n",
    "    weights = best_gmm.weights_.flatten()\n",
    "    hi = np.argmax(means)\n",
    "    frac_resistant = float(weights[hi])\n",
    "    delta_means = float(np.max(means) - np.min(means)) if best_k > 1 else 0.0\n",
    "    return best_k, frac_resistant, delta_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc36274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_rows = []\n",
    "percell_store = []  # optional: store per-cell predictions (can be large)\n",
    "\n",
    "for drug_id in BEST_DRUGS:\n",
    "    bundle_path = os.path.join(MODELS_DIR, f\"elasticnet_drug{drug_id}.joblib\")\n",
    "    if not os.path.exists(bundle_path):\n",
    "        print(f\"Missing model for drug {drug_id}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load model bundle\n",
    "    bundle = joblib.load(bundle_path)\n",
    "    model  = bundle[\"model\"]\n",
    "    scaler = bundle[\"scaler\"]\n",
    "    gene_cols = bundle[\"gene_cols\"]  # expected SIDG column order\n",
    "\n",
    "    # Align sc features to model's gene order; fill missing genes with zeros\n",
    "    present = [g for g in gene_cols if g in sc_line.columns]\n",
    "    if len(present) == 0:\n",
    "        print(f\"Drug {drug_id}: no overlapping genes â€” skipping.\")\n",
    "        continue\n",
    "\n",
    "    X = np.zeros((sc_line.shape[0], len(gene_cols)), dtype=float)\n",
    "    col_index = {g:i for i,g in enumerate(sc_line.columns)}\n",
    "    for j, g in enumerate(gene_cols):\n",
    "        if g in col_index:\n",
    "            X[:, j] = sc_line.iloc[:, col_index[g]].values\n",
    "\n",
    "    # Scale and predict\n",
    "    X_scaled = scaler.transform(X)\n",
    "    y_pred_cell = model.predict(X_scaled)\n",
    "\n",
    "    # Calibrate to bulk scale (if calibration exists)\n",
    "    slope, intercept = load_calibration(drug_id)\n",
    "    y_pred_cell_cal = y_pred_cell * slope + intercept\n",
    "\n",
    "    # Summaries for this cell line & drug\n",
    "    n_cells = len(y_pred_cell_cal)\n",
    "    mean_ = float(np.mean(y_pred_cell_cal))\n",
    "    med_  = float(np.median(y_pred_cell_cal))\n",
    "    q10_  = float(np.quantile(y_pred_cell_cal, 0.10))\n",
    "    q90_  = float(np.quantile(y_pred_cell_cal, 0.90))\n",
    "    k_, frac_res_, dmu_ = heterogeneity_metrics(y_pred_cell_cal)\n",
    "\n",
    "    # Bulk truth for this line (if present)\n",
    "    ln_ic50_bulk = gdsc_line.loc[gdsc_line[\"DRUG_ID\"] == drug_id, \"LN_IC50\"]\n",
    "    ln_ic50_bulk = float(ln_ic50_bulk.values[0]) if len(ln_ic50_bulk) else np.nan\n",
    "    delta = mean_ - ln_ic50_bulk if not np.isnan(ln_ic50_bulk) else np.nan\n",
    "\n",
    "    summ_rows.append({\n",
    "        \"SANGER_MODEL_ID\": SANGER_ID,\n",
    "        \"DRUG_ID\": drug_id,\n",
    "        \"n_cells\": n_cells,\n",
    "        \"pred_mean_cal\": mean_,\n",
    "        \"pred_median_cal\": med_,\n",
    "        \"pred_q10_cal\": q10_,\n",
    "        \"pred_q90_cal\": q90_,\n",
    "        \"hetero_k\": k_,\n",
    "        \"hetero_frac_resistant\": frac_res_,\n",
    "        \"hetero_delta_means\": dmu_,\n",
    "        \"bulk_LN_IC50\": ln_ic50_bulk,\n",
    "        \"mean_minus_bulk\": delta,\n",
    "        \"calib_slope\": slope,\n",
    "        \"calib_intercept\": intercept\n",
    "    })\n",
    "\n",
    "    # (Optional) keep per-cell values (comment out if large)\n",
    "    percell_store.append(pd.DataFrame({\n",
    "        \"cell_id\": sc_line.index,\n",
    "        \"SANGER_MODEL_ID\": SANGER_ID,\n",
    "        \"DRUG_ID\": drug_id,\n",
    "        \"pred_cell_cal\": y_pred_cell_cal\n",
    "    }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d395f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(summ_rows)\n",
    "\n",
    "# Lower LN_IC50 = more sensitive\n",
    "summary_sorted = summary.sort_values(\"pred_mean_cal\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "print(\"Top predicted sensitive drugs for\", SANGER_ID)\n",
    "display(summary_sorted[[\"DRUG_ID\",\"pred_mean_cal\",\"pred_q10_cal\",\"pred_q90_cal\",\"bulk_LN_IC50\",\"mean_minus_bulk\"]])\n",
    "\n",
    "# Save\n",
    "sum_path = os.path.join(OUTDIR, f\"{SANGER_ID}_sc_predictions_vs_bulk.csv\")\n",
    "summary_sorted.to_csv(sum_path, index=False)\n",
    "print(\"Saved summary:\", sum_path)\n",
    "\n",
    "# (Optional) save per-cell predictions\n",
    "if len(percell_store):\n",
    "    percell_df = pd.concat(percell_store, ignore_index=True)\n",
    "    pc_path = os.path.join(OUTDIR, f\"{SANGER_ID}_percell_predictions.csv\")\n",
    "    percell_df.to_csv(pc_path, index=False)\n",
    "    print(\"Saved per-cell predictions:\", pc_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c0a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_n = 10  # show all selected drugs\n",
    "plot_df = summary_sorted.head(top_n).copy()\n",
    "plt.figure(figsize=(8, 4 + 0.25*top_n))\n",
    "\n",
    "# error bars from q10 to q90 around mean\n",
    "ypos = np.arange(len(plot_df))\n",
    "plt.errorbar(plot_df[\"pred_mean_cal\"], ypos,\n",
    "             xerr=[plot_df[\"pred_mean_cal\"] - plot_df[\"pred_q10_cal\"],\n",
    "                   plot_df[\"pred_q90_cal\"] - plot_df[\"pred_mean_cal\"]],\n",
    "             fmt='o', capsize=3, label=\"Predicted (mean Â± q10â€“q90)\")\n",
    "\n",
    "# overlay bulk truth if available\n",
    "if plot_df[\"bulk_LN_IC50\"].notna().any():\n",
    "    plt.scatter(plot_df[\"bulk_LN_IC50\"], ypos, marker='x', label=\"Bulk LN_IC50\")\n",
    "\n",
    "plt.yticks(ypos, plot_df[\"DRUG_ID\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"LN_IC50 (lower = more sensitive)\")\n",
    "plt.title(f\"{SANGER_ID}: predicted single-cell drug response vs bulk\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tese-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
